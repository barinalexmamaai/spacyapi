{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e66b01-3893-4379-b315-ede82efeb6d8",
   "metadata": {},
   "source": [
    "## fine tune bert model for custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48530009-5e4d-45aa-875e-4bbb02b9b577",
   "metadata": {},
   "source": [
    "### 1. install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1979f468-fe07-4724-9749-2f6af83bc484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (4.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: filelock in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (2021.11.2)\n",
      "Requirement already satisfied: sacremoses in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (4.63.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: click in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /home/barinale/miniconda3/envs/ner/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b538518-a536-4fda-b99f-0af0929f7294",
   "metadata": {},
   "source": [
    "### 2. load/define data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f665b5-5346-4a77-9ec5-dc4813f2d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02865faf-014d-41b5-8841-63729890d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dummydata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c2f9f66-0d45-4f8d-b387-116c1b9b739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['intlabel'] = df['label'].rank(method='dense', ascending=False).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e17d6e9-9c18-47ff-b831-4bdd8d006faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.text.tolist()\n",
    "labels = df.intlabel.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6b7b874-5868-4011-ab3a-7c8c66c5043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f788fd68-d980-4899-96a8-890bf40e8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trntxt, tsttxt, trnlbl, tstlbl = train_test_split(texts, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec86c1d9-d1e6-4bde-a4e4-10f4e6b59adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I don't want it\", 'stop it', 'cancel', 'well, ok', 'nah'] [1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tsttxt, tstlbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5cdb658-624b-4c7d-b336-5db4f8c2299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['train'] = [{'text': txt, 'lable': lbl} for txt, lbl in zip(trntxt, trnlbl)]\n",
    "data['test'] = [{'text': txt, 'lable': lbl} for txt, lbl in zip(tsttxt, tstlbl)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a444710-8953-4fe6-8f24-2f326588602f",
   "metadata": {},
   "source": [
    "### 3. preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6fb0ba6-d503-43ca-8420-3d6c51c4b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48eaceeb-774c-4956-aa69-1ef2c5986d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the same tokenizer a model was trained with\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb496c93-67fa-42a0-8d10-94cbb7eecc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trnencodings = tokenizer(trntxt, truncation=True, padding=True)\n",
    "tstencodings = tokenizer(tsttxt, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "28ce02ba-3e23-454c-8f6a-08a36183d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(trnencodings),\n",
    "    trnlbl\n",
    "))\n",
    "tst_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tstencodings),\n",
    "    tstlbl\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ce3fc-994a-4abe-a0b2-bfd9e2ad1516",
   "metadata": {},
   "source": [
    "### 4. load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af7027aa-917e-4237-849e-48c0cee7e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0281ca1e-bbcb-4897-bb5e-032fd0a98b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_layer_norm', 'activation_13', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_79']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7163b409-6e81-47d6-b1d7-692bf5468abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2/2 [==============================] - 12s 3s/step - loss: 1.0739 - accuracy: 0.5033 - val_loss: 1.2039 - val_accuracy: 0.2000\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 2s 766ms/step - loss: 1.0407 - accuracy: 0.5175 - val_loss: 1.2357 - val_accuracy: 0.2000\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 1s 676ms/step - loss: 0.9948 - accuracy: 0.7204 - val_loss: 1.3023 - val_accuracy: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f59704b3350>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])\n",
    "model.fit(trn_dataset.shuffle(100).batch(16),\n",
    "          epochs=3,\n",
    "          batch_size=16,\n",
    "          validation_data=tst_dataset.shuffle(100).batch(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfffd4-6b79-4a8a-8a88-687f6793ac25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
